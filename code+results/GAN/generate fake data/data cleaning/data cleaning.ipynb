{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a82cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trained generator-model\n",
    "fake_data_model= load_model('/home/hashemi/Fei Shao/WGAN_2.5_100epoch.h5')\n",
    "batch_size = 1700 # Adjust parameters to generate any number of fake data \n",
    "noise = np.random.normal(loc=0, scale=1, size=(batch_size, 8)) # feed noise\n",
    "generated_data = fake_data_model.predict(noise)\n",
    "\n",
    "# save generated_data(fake data) before data cleaning into Excel\n",
    "data = pd.DataFrame(generated_data)\n",
    "data.to_excel('/home/hashemi/Fei Shao/fake_2.5.xlsx', index=False)\n",
    "\n",
    "# read fake data\n",
    "faketrain_data = pd.read_excel('/home/hashemi/Fei Shao/fake_2.5.xlsx', dtype=np.float32)\n",
    "faketrain_data\n",
    "\n",
    "# data cleaning (WGAN trained 3 generator model for particle 1.5mm, 2.5mm, 3.5mm,\n",
    "#so there needs to do 3 data cleaning for each size particle.)\n",
    "from decimal import Decimal\n",
    "# restore magnitude order\n",
    "faketrain_data.loc[:,0] = 2.5 # if gennrator model is for all size, like flowrate in SME,here need to be some changed\n",
    "faketrain_data.iloc[:,1] = (faketrain_data.iloc[:,1]*100).astype(int)/100\n",
    "faketrain_data.iloc[:,2] = (faketrain_data.iloc[:,2]*100).astype(int)/100\n",
    "faketrain_data.iloc[:,3] = round(faketrain_data.iloc[:,3]/100000, 3)\n",
    "faketrain_data.iloc[:,4] = (faketrain_data.iloc[:,4]*10).astype(int)\n",
    "faketrain_data.iloc[:,5] = (faketrain_data.iloc[:,5]/100).astype(int)\n",
    "faketrain_data.iloc[:,6] = round(faketrain_data.iloc[:,6]/10000, 2)\n",
    "faketrain_data.iloc[:,7] = round(faketrain_data.iloc[:,7]/10000, 2) \n",
    "# delete all rows with negative values\n",
    "faketrain_data = faketrain_data[(faketrain_data > 0).all(axis=1)] \n",
    "# delete all rows where the friction coefficient is greater than 1 (Remove parameters that do not conform to physics)\n",
    "faketrain_data = faketrain_data.drop(faketrain_data[faketrain_data.iloc[:,6]>1].index)  \n",
    "\n",
    "# save fakedata after data cleaning\n",
    "faketrain_data.reset_index(drop=True, inplace=True)\n",
    "faketrain_data\n",
    "faketrain_data.to_excel('/home/hashemi/Fei Shao/fake_2.5clean_.xlsx', index=False)\n",
    "\n",
    "# combine the fake data together\n",
    "df1 = pd.read_excel('/home/hashemi/Fei Shao/fake_1.5clean_.xlsx')\n",
    "df2 = pd.read_excel('/home/hashemi/Fei Shao/fake_2.5clean_.xlsx')\n",
    "df3 = pd.read_excel('/home/hashemi/Fei Shao/fake_4.5clean_.xlsx')\n",
    "frames = [df1, df2, df3]\n",
    "df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# combine the fake data set with original data set\n",
    "df0 = pd.read_excel('/home/hashemi/Fei Shao/total.xlsx')\n",
    "frames = [df0, df]\n",
    "dataframe = pd.concat(frames)\n",
    "dataframe.to_excel('/home/hashemi/Fei Shao/total_fake.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
